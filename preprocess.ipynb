{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/_fnn1tf53cz1df_1wxhgm5m00000gn/T/ipykernel_12518/2486457676.py:31: DtypeWarning: Columns (5,108,121,196,197,198) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs_by_year = {year: pd.read_csv(path) for year, path in paths_to_csv_by_year.items()}\n",
      "/var/folders/y5/_fnn1tf53cz1df_1wxhgm5m00000gn/T/ipykernel_12518/2486457676.py:31: DtypeWarning: Columns (8,12,13,14,15,16,50,51,52,53,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs_by_year = {year: pd.read_csv(path) for year, path in paths_to_csv_by_year.items()}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Column(Enum):\n",
    "    SALARY = \"salary\"\n",
    "    COUNTRY = \"country\"\n",
    "    COUNTRY_CODE = \"country_code\"\n",
    "    YEARS_OF_EXPERIENCE = \"years_of_experience\"\n",
    "    AGE = \"age\"\n",
    "    PROGRAMMING_LANGUAGE = \"language\"\n",
    "\n",
    "\n",
    "paths_to_csv_by_year = {\n",
    "    \"2015\": Path(\"data/raw/2015 Stack Overflow Developer Survey Responses.csv\"),\n",
    "    \"2016\": Path(\"data/raw/2016 Stack Overflow Survey Results/2016 Stack Overflow Survey Responses.csv\"),\n",
    "    \"2017\": Path(\"data/raw/stack-overflow-developer-survey-2017/survey_results_public.csv\"),\n",
    "    \"2018\": Path(\"data/raw/stack-overflow-developer-survey-2018/survey_results_public.csv\"),\n",
    "    \"2019\": Path(\"data/raw/stack-overflow-developer-survey-2019/survey_results_public.csv\"),\n",
    "    \"2020\": Path(\"data/raw/stack-overflow-developer-survey-2020/survey_results_public.csv\"),\n",
    "    \"2021\": Path(\"data/raw/stack-overflow-developer-survey-2021/survey_results_public.csv\"),\n",
    "    \"2022\": Path(\"data/raw/stack-overflow-developer-survey-2022/survey_results_public.csv\"),\n",
    "    \"2023\": Path(\"data/raw/stack-overflow-developer-survey-2023/survey_results_public.csv\"),\n",
    "    \"2024\": Path(\"data/raw/stack-overflow-developer-survey-2024/survey_results_public.csv\"),\n",
    "}\n",
    "\n",
    "# TODO: if not found, supply URL and download them\n",
    "dfs_by_year = {year: pd.read_csv(path) for year, path in paths_to_csv_by_year.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unify the datasets\n",
    "\n",
    "- rename columns to uniform names\n",
    "- convert years/age ranges (e.g. \"20 to 30 years old\") to values (using interval midpoints)\n",
    "- remove rows that have missing values for salary, programming langs, country or years of experience\n",
    "- approximate age using years of experience if the column is missing (in the 2017 survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map_2021_and_later = {\n",
    "    Column.SALARY: \"ConvertedCompYearly\",\n",
    "    Column.COUNTRY: \"Country\",\n",
    "    Column.COUNTRY_CODE: None,\n",
    "    Column.YEARS_OF_EXPERIENCE: \"YearsCode\",\n",
    "    Column.AGE: \"Age\",\n",
    "    Column.PROGRAMMING_LANGUAGE: \"LanguageHaveWorkedWith\",\n",
    "}\n",
    "\n",
    "colum_map_by_year = {\n",
    "    \"2016\": {\n",
    "        Column.SALARY: \"salary_midpoint\",\n",
    "        Column.COUNTRY: \"country\",\n",
    "        Column.COUNTRY_CODE: None,\n",
    "        Column.YEARS_OF_EXPERIENCE: \"experience_midpoint\",\n",
    "        Column.AGE: \"age_midpoint\",\n",
    "        Column.PROGRAMMING_LANGUAGE: \"tech_do\",\n",
    "    },\n",
    "    \"2017\": {\n",
    "        Column.SALARY: \"Salary\",\n",
    "        Column.COUNTRY: \"Country\",\n",
    "        Column.COUNTRY_CODE: None,\n",
    "        Column.YEARS_OF_EXPERIENCE: \"YearsProgram\",\n",
    "        Column.AGE: None,  # Approximated YearsProgram + 23\n",
    "        Column.PROGRAMMING_LANGUAGE: \"HaveWorkedLanguage\"\n",
    "    },\n",
    "    \"2018\": {\n",
    "        Column.SALARY: \"ConvertedSalary\",\n",
    "        Column.COUNTRY: \"Country\",\n",
    "        Column.COUNTRY_CODE: None,\n",
    "        Column.YEARS_OF_EXPERIENCE: \"YearsCoding\",\n",
    "        Column.AGE: \"Age\",\n",
    "        Column.PROGRAMMING_LANGUAGE: \"LanguageWorkedWith\",\n",
    "    },\n",
    "    \"2019\": {\n",
    "        Column.SALARY: \"ConvertedComp\",\n",
    "        Column.COUNTRY: \"Country\",\n",
    "        Column.COUNTRY_CODE: None,\n",
    "        Column.YEARS_OF_EXPERIENCE: \"YearsCode\",\n",
    "        Column.AGE: \"Age\",\n",
    "        Column.PROGRAMMING_LANGUAGE: \"LanguageWorkedWith\",\n",
    "    },\n",
    "    \"2020\": {\n",
    "        Column.SALARY: \"ConvertedComp\",\n",
    "        Column.COUNTRY: \"Country\",\n",
    "        Column.COUNTRY_CODE: None,\n",
    "        Column.YEARS_OF_EXPERIENCE: \"YearsCode\",\n",
    "        Column.AGE: \"Age\",\n",
    "        Column.PROGRAMMING_LANGUAGE: \"LanguageWorkedWith\",\n",
    "    },\n",
    "    \"2021\": column_map_2021_and_later,\n",
    "    \"2022\": column_map_2021_and_later,\n",
    "    \"2023\": column_map_2021_and_later,\n",
    "    \"2024\": column_map_2021_and_later,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert years/age ranges to values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_years_and_age(df: pd.DataFrame):\n",
    "    def convert_to_numeric(value):\n",
    "        if pd.isnull(value):\n",
    "            return None\n",
    "        if isinstance(value, (int, float)):  # If already a number, return it\n",
    "            return float(value)\n",
    "        value = str(value)\n",
    "\n",
    "        # Match patterns and convert accordingly\n",
    "        if re.match(r'^\\d+$', value):\n",
    "            return float(value)\n",
    "        elif match := re.match(r'^(\\d+)\\s*years?', value):\n",
    "            return float(match.group(1))\n",
    "        elif match := re.match(r'^(\\d+)\\s*to\\s*(\\d+)', value):\n",
    "            return (float(match.group(1)) + float(match.group(2))) / 2\n",
    "        elif match := re.match(r'^(\\d+)[\\s\\-]+(\\d+)', value):\n",
    "            return (float(match.group(1)) + float(match.group(2))) / 2\n",
    "        elif match := re.match(r'^(\\d+)\\s*and\\s*more', value):\n",
    "            return float(match.group(1)) + 1\n",
    "        elif match := re.match(r'^(\\d+)\\s*or\\s*more', value):\n",
    "            return float(match.group(1)) + 1\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Apply conversion to specified columns\n",
    "    df[Column.YEARS_OF_EXPERIENCE.value] = df[Column.YEARS_OF_EXPERIENCE.value].apply(convert_to_numeric)\n",
    "    df[Column.AGE.value] = df[Column.AGE.value].apply(convert_to_numeric)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract uniform country codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "import country_converter as coco\n",
    "import logging\n",
    "\n",
    "country_converter = coco.CountryConverter(include_obsolete=True)\n",
    "\n",
    "# Do not log warnings from coco (if match is not found)\n",
    "logging.basicConfig(level=logging.ERROR, force=True)\n",
    "\n",
    "# Function to get ISO Alpha-2 code\n",
    "def get_country_code(country_name: str):\n",
    "    try:\n",
    "        # Faster but less robust pycountry matcher\n",
    "        country = pycountry.countries.lookup(country_name.strip())\n",
    "        return country.alpha_2\n",
    "    except LookupError:\n",
    "        # Fallback to coco which is more robust but slower\n",
    "        country = country_converter.convert(names=country_name, to='ISO2', not_found='NOT-FOUND')\n",
    "        return None if country == 'NOT-FOUND' else country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply everything on the datasets and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 40904 rows for year 2016\n",
      "Extracted 12120 rows for year 2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/_fnn1tf53cz1df_1wxhgm5m00000gn/T/ipykernel_12518/2029844218.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[Column.AGE.value] = df[Column.AGE.value].fillna(df[Column.YEARS_OF_EXPERIENCE.value] + 23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 46467 rows for year 2018\n",
      "Extracted 55537 rows for year 2019\n",
      "Extracted 33333 rows for year 2020\n",
      "Extracted 46329 rows for year 2021\n",
      "Extracted 37891 rows for year 2022\n",
      "Extracted 47820 rows for year 2023\n",
      "Extracted 23309 rows for year 2024\n"
     ]
    }
   ],
   "source": [
    "save_path = Path(\"data/extracted\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Do not log warnings from coco (if match is not found)\n",
    "logging.basicConfig(level=logging.ERROR, force=True)\n",
    "\n",
    "dfs_normalized_by_year = {}\n",
    "\n",
    "for year, df in dfs_by_year.items():\n",
    "    if year not in colum_map_by_year:\n",
    "        continue\n",
    "\n",
    "    # Extract relevant columns\n",
    "    column_map = colum_map_by_year[year]\n",
    "    columns = [column_map[col] for col in Column if column_map[col] is not None]\n",
    "    df = df[columns]\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = [col.value for col in Column if column_map[col] is not None]\n",
    "\n",
    "    # Remove rows that don't have salary, language, country or years of experience\n",
    "    df = df.dropna(subset=[Column.SALARY.value, Column.PROGRAMMING_LANGUAGE.value, Column.COUNTRY.value, Column.YEARS_OF_EXPERIENCE.value])\n",
    "\n",
    "\n",
    "    # Year 2017 does not have age column, set values to None\n",
    "    if year == \"2017\":\n",
    "        df[Column.AGE.value] = None\n",
    "\n",
    "    # Convert y.o.e and age from range to numeric\n",
    "    df = convert_years_and_age(df)\n",
    "    print(f\"Extracted {len(df)} rows for year {year}\")\n",
    "\n",
    "    # Approximate age with years of experience + 23 if it's nan\n",
    "    df[Column.AGE.value] = df[Column.AGE.value].fillna(df[Column.YEARS_OF_EXPERIENCE.value] + 23)\n",
    "\n",
    "    # Standardize country names e.g. [USA, United States, ...] to country codes (US)\n",
    "    df[Column.COUNTRY_CODE.value] = df[Column.COUNTRY.value].apply(get_country_code)\n",
    "\n",
    "    # Remove rows with no country code (couldn't be matched, there's just 10-20 of them)\n",
    "    df = df.dropna(subset=[Column.COUNTRY_CODE.value])\n",
    "\n",
    "    df.to_csv(save_path / f\"{year}.csv\", index=False)\n",
    "    dfs_normalized_by_year[year] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend over language column\n",
    "\n",
    "now the `language` column contains multiple programming languages concat'd by a delimiter e.g. \"Python; R; SQL\". We will split the rows into multiple rows, each containing a single language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def parse_language(lang: str) -> Optional[str]:\n",
    "    lang = lang.strip()\n",
    "\n",
    "    if lang in [\"CSS\", \"SQL\", \"SQL Server\", \"MongoDB\", \"Node.js\"]:\n",
    "        # Let's be real, these are not real programming languages\n",
    "        return None\n",
    "\n",
    "    if \"bash\" in lang.lower() or \"html\" in lang.lower():\n",
    "        return None\n",
    "    \n",
    "    return lang\n",
    "\n",
    "def expand_by_language(df: pd.DataFrame):\n",
    "    # Create an empty list to store the expanded rows\n",
    "    expanded_rows = []\n",
    "\n",
    "    # Iterate over the rows of the dataframe\n",
    "    for _, row in df.iterrows():\n",
    "        # Split the 'language' column by ';'\n",
    "        languages = row[Column.PROGRAMMING_LANGUAGE.value].split(';')\n",
    "\n",
    "        # For each language, create a new row with the same values but different language\n",
    "        for language in languages:\n",
    "            language = parse_language(language)\n",
    "            if language is None:\n",
    "                continue\n",
    "\n",
    "            expanded_row = row.copy() \n",
    "            expanded_row[Column.PROGRAMMING_LANGUAGE.value] = language\n",
    "            expanded_rows.append(expanded_row)\n",
    "\n",
    "    # Convert the list of expanded rows back into a DataFrame\n",
    "    expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: 40883 rows expanded to 150780 rows\n",
      "2017: 12107 rows expanded to 38152 rows\n",
      "2018: 46428 rows expanded to 180642 rows\n",
      "2019: 55477 rows expanded to 189266 rows\n",
      "2020: 33319 rows expanded to 113856 rows\n",
      "2021: 46311 rows expanded to 166636 rows\n",
      "2022: 37875 rows expanded to 137698 rows\n",
      "2023: 47803 rows expanded to 180633 rows\n",
      "2024: 23305 rows expanded to 90008 rows\n"
     ]
    }
   ],
   "source": [
    "save_path = Path(\"data/expanded\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "expanded_df_by_year = {}\n",
    "\n",
    "\n",
    "for year, df in dfs_normalized_by_year.items():\n",
    "    df_expanded = expand_by_language(df)\n",
    "\n",
    "    print(f\"{year}: {len(df)} rows expanded to {len(df_expanded)} rows\")\n",
    "\n",
    "\n",
    "    expanded_df_by_year[year] = df_expanded\n",
    "\n",
    "    df_expanded.to_csv(save_path / f\"{year}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets the data for top `n` languages\n",
    "\n",
    "- since there are many too many unique programming languages visualizing all of them would result in cluttered graphs\n",
    "- subset only the top `n` most popular languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "JavaScript: 229561\n",
      "Python: 136597\n",
      "Java: 118539\n",
      "C#: 108292\n",
      "TypeScript: 96040\n",
      "PHP: 79343\n",
      "C++: 64345\n",
      "C: 52790\n",
      "Go: 33922\n",
      "Ruby: 29786\n",
      "Kotlin: 22364\n",
      "PowerShell: 20826\n",
      "Swift: 20284\n",
      "Rust: 19194\n",
      "R: 15494\n",
      "Objective-C: 15295\n",
      "VBA: 13787\n",
      "Scala: 12689\n",
      "Assembly: 12199\n",
      "Dart: 10433\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Initialize a Counter to accumulate language occurrences across all years\n",
    "language_counter = Counter()\n",
    "\n",
    "print(len(expanded_df_by_year))\n",
    "\n",
    "for year, df in expanded_df_by_year.items():\n",
    "    # Count the occurrences of each language in the expanded dataframe\n",
    "    language_counts = df[Column.PROGRAMMING_LANGUAGE.value].value_counts()\n",
    "    # Update the Counter with the language counts as a dictionary\n",
    "    language_counter.update(language_counts.to_dict())\n",
    "\n",
    "# After processing all years, print the overall language counts sorted by occurrence\n",
    "sorted_language_counts = language_counter.most_common()\n",
    "\n",
    "n = 20\n",
    "top_n_languages = sorted_language_counts[:n]\n",
    "\n",
    "# Print the top n languages\n",
    "for language, count in top_n_languages:\n",
    "    print(f\"{language}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all irrelevant rows from the dataframes (ones that are not related to top 20 programming languages by popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = Path(\"data/cleaned\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "top_languages_set = {lang for lang, _ in top_n_languages}\n",
    "\n",
    "df_clean_by_year = {}\n",
    "\n",
    "for year, df in expanded_df_by_year.items():\n",
    "    # Filter out rows with languages that are not in the top n languages\n",
    "    df_clean = df[df[Column.PROGRAMMING_LANGUAGE.value].isin(top_languages_set)]\n",
    "\n",
    "    # Due to some bug in my code <0.1% of data still has some NaN values, drop them\n",
    "    df_clean = df_clean.dropna()\n",
    "    print(f\"{year}: {len(df)} rows filtered to {len(df_clean)} rows\")\n",
    "\n",
    "    df_clean_by_year[year] = df_clean\n",
    "    df_clean.to_csv(save_path / f\"{year}.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
